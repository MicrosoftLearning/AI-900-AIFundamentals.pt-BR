{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Análise de Texto\r\n",
        "\r\n",
        "O Processamento de Linguagem Natural (PLN) é um ramo da inteligência artificial (IA) que lida com a linguagem escrita e falada. Você pode usar o PLN para criar soluções que extraem o significado semântico de textos e falas ou formulam respostas significativas em linguagem natural.\r\n",
        "\r\n",
        "Os *Serviços Cognitivos* do Microsoft Azure incluem o serviço de *Análise de Texto*, que oferece alguns recursos de PLN prontos para usar, inclusive a identificação de frases-chave no texto e a classificação de textos com base em sentimentos.\r\n",
        "\r\n",
        "![Um robô lendo um notebook](./images/NLP.jpg)\r\n",
        "\r\n",
        "Por exemplo, suponha que a empresa fictícia *Margie’s Travel* incentive os clientes a enviar análises de suas estadias em hotéis. Você pode usar o serviço de Análise de Texto para resumir as análises extraindo frases-chave, determinar quais delas são positivas e quais são negativas ou examinar o texto da análise em busca de menções a entidades conhecidas, como locais ou pessoas.\r\n",
        "\r\n",
        "## Ver documentos de análise\r\n",
        "\r\n",
        "Vamos começar dando uma olhada em algumas análises de hotéis que foram deixadas pelos clientes.\r\n",
        "\r\n",
        "As análises estão em arquivos de texto. Para vê-las, basta executar o código abaixo clicando no botão **Executar célula** (&#9655;) à esquerda."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the reviews in the /data/reviews folder\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
        "\n",
        "# Create a collection of reviews with id (file name) and text (contents) properties\r\n",
        "reviews = []\n",
        "for file_name in os.listdir(reviews_folder):\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
        "    review = {\"id\": file_name, \"text\": review_text}\n",
        "    reviews.append(review)\n",
        "\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review text\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Criar um recurso dos Serviços Cognitivos\r\n",
        "\r\n",
        "Para examinar o texto dessas análises, use o serviço cognitivo de **Análise de Texto**. Para isso, é preciso provisionar um recurso de **Análise de Texto** ou **Serviços Cognitivos** na sua assinatura do Azure. (Use um recurso de Análise de Texto se esse for o único serviço que você pretende usar ou se quiser acompanhar a utilização separadamente. Caso contrário, poderá usar um recurso dos Serviços Cognitivos para combinar o serviço de Análise de Texto com outros serviços cognitivos, o que permite que os desenvolvedores usem um único ponto de extremidade e chave para acessá-los).\r\n",
        "\r\n",
        "Caso você ainda não tenha um, use as etapas a seguir para criar um recurso dos **Serviços Cognitivos** na sua assinatura do Azure:\r\n",
        "\r\n",
        "> **Observação**: Se você já tiver um recurso dos Serviços Cognitivos, abra a página de **Início Rápido** no portal do Azure e copie a respectiva chave e o ponto de extremidade para a célula abaixo. Caso contrário, siga as etapas abaixo para criar um.\r\n",
        "\r\n",
        "1. Em outra guia do navegador, abra o portal do Azure em https://portal.azure.com, entrando com sua conta Microsoft.\r\n",
        "2. Clique no botão **&#65291;Criar um recurso**, procure *Serviços Cognitivos* e crie um recurso dos **Serviços Cognitivos** com as configurações abaixo:\r\n",
        "    - **Assinatura**: *sua assinatura do Azure*.\r\n",
        "    - **Grupo de recursos**: *Selecione ou crie um grupo de recursos com um nome exclusivo*.\r\n",
        "    - **Região**: *Escolha qualquer região disponível*:\r\n",
        "    - **Nome**: *Insira um nome exclusivo*.\r\n",
        "    - **Tipo de preço**: S0\r\n",
        "    - **Confirmo que li e entendi os avisos**: Selecionado.\r\n",
        "3. Aguarde até que a implantação seja concluída. Depois, entre em seu recurso dos Serviços Cognitivos e, na página **Visão geral**, clique no link para gerenciar as chaves do serviço. Você precisará do ponto de extremidade e das chaves para se conectar aos seus recursos dos Serviços Cognitivos em aplicativos clientes.\r\n",
        "\r\n",
        "### Obter a chave e o ponto de extremidade do seu recurso dos Serviços Cognitivos\r\n",
        "\r\n",
        "Para usar seu recurso dos Serviços Cognitivos, os aplicativos clientes precisam do ponto de extremidade e da chave de autenticação:\r\n",
        "\r\n",
        "1. No portal do Azure, na página **Chaves e ponto de extremidade** do seu recurso dos Serviços Cognitivos, copie a **Chave 1** do recurso e cole no código abaixo, substituindo **YOUR_COG_KEY**.\r\n",
        "2. Copie o **ponto de extremidade** do recurso e cole no código abaixo, substituindo **YOUR_COG_ENDPOINT**.\r\n",
        "3. Execute o código da célula abaixo clicando no botão verde <span style=\"color:green\">&#9655;</span>."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detectar idioma\r\n",
        "Vamos começar identificando o idioma em que essas análises foram escritas."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "# Get a client for your text analytics cognitive service resource\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Analyze the reviews you read from the /data/reviews folder earlier\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
        "\n",
        "# print detected language details for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the language details for this review\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
        "\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extrair frases-chave\r\n",
        "\r\n",
        "Agora você já pode examinar o texto das análises dos clientes para identificar frases-chave que indicam os principais pontos discutidos."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the client and reviews you created in the previous code cell to get key phrases\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
        "\n",
        "# print key phrases for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the key phrases in this review\n",
        "    print('\\nKey Phrases:')\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
        "    # Print each key phrase\n",
        "    for key_phrase in key_phrases:\n",
        "        print('\\t', key_phrase)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As frases-chave podem ajudar você a entender os principais pontos de discussão de cada análise. Por exemplo, uma análise que contenha a frase \"equipe prestativa\" ou \"atendimento ruim\" pode dar pistas sobre algumas das principais preocupações do avaliador.\r\n",
        "\r\n",
        "## Determinar o sentimento\r\n",
        "\r\n",
        "Talvez seja útil classificar as análises como *positivas* ou *negativas* de acordo com uma *pontuação de sentimento*. De novo, você pode usar o serviço de Análise de Texto para isso."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get sentiment scores\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "\n",
        "    # Get the sentiment score for this review\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
        "\n",
        "    # classifiy 'positive' if more than 0.5, \n",
        "    if sentiment_score < 0.5:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    # print file name and sentiment\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extrair entidades conhecidas\r\n",
        "\r\n",
        "*Entidades* são coisas que podem ser mencionadas no texto e fazem referência a algum tipo de item de compreensão comum. Por exemplo, um local, uma pessoa ou uma data. Vamos supor que você esteja interessado em datas e locais mencionados nas análises. Você poderá usar o código abaixo para identificá-los."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get named entities\r\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only print datetime or location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note que algumas entidades são conhecidas o bastante para ter uma página da Wikipedia associada a elas. Nesses casos, o serviço de Análise de Texto retorna o URL dessa página.\r\n",
        "\r\n",
        "## Saiba mais\r\n",
        "\r\n",
        "Para mais informações sobre o serviço de Análise de Texto, consulte a [documentação do serviço](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}