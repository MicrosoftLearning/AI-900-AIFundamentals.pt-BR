{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção e análise de rostos\n",
    "\n",
    "Soluções de Pesquisa Visual Computacional geralmente exigem uma solução de inteligência artificial (IA) para poder detectar, analisar ou identificar rostos humanos. Por exemplo, suponha que a empresa de varejo Northwind Traders tenha decidido implementar uma \"loja inteligente\", em que serviços de IA monitoram o estabelecimento para identificar os clientes que precisam de ajuda e direcionar funcionários para auxiliá-los. Uma maneira de fazer isso é realizando detecção e análise facial (em outras palavras, determinar se existe algum rosto nas imagens e, em caso positivo, analisar suas características).\n",
    "\n",
    "![Um robô analisando um rosto](./images/face_analysis.jpg)\n",
    "\n",
    "## Usar o serviço cognitivo Detecção Facial para detectar rostos\n",
    "\n",
    "Suponha que o sistema de loja inteligente que a Northwind Traders quer criar precise ser capaz de detectar clientes e analisar suas características faciais. No Microsoft Azure, você pode usar a **Detecção Facial**, parte dos Serviços Cognitivos do Azure para fazer isso.\n",
    "\n",
    "### Criar um recurso dos Serviços Cognitivos\n",
    "\n",
    "Vamos começar criando um recurso dos **Serviços Cognitivos** na sua assinatura do Azure.\n",
    "\n",
    "> **Observação**: Se você já tiver um recurso dos Serviços Cognitivos, abra a página de **Início Rápido** no portal do Azure e copie a respectiva chave e o ponto de extremidade para a célula abaixo. Caso contrário, siga as etapas abaixo para criar um.\n",
    "\n",
    "1. Em outra guia do navegador, abra o portal do Azure em https://portal.azure.com, entrando com sua conta Microsoft.\n",
    "2. Clique no botão **&#65291;Criar um recurso**, procure *Serviços Cognitivos* e crie um recurso dos **Serviços Cognitivos** com as configurações abaixo:\n",
    "    - **Assinatura**: *sua assinatura do Azure*.\n",
    "    - **Grupo de recursos**: *Selecione ou crie um grupo de recursos com um nome exclusivo*.\n",
    "    - **Região**: *Escolha qualquer região disponível*:\n",
    "    - **Nome**: *Insira um nome exclusivo*.\n",
    "    - **Tipo de preço**: S0\n",
    "    - **Confirmo que li e entendi os avisos**: Selecionado.\n",
    "3. Aguarde até que a implantação seja concluída. Depois, entre em seu recurso dos Serviços Cognitivos e, na página **Visão geral**, clique no link para gerenciar as chaves do serviço. Você precisará do ponto de extremidade e das chaves para se conectar aos seus recursos dos Serviços Cognitivos em aplicativos clientes.\n",
    "\n",
    "### Obter a chave e o ponto de extremidade do seu recurso dos Serviços Cognitivos\n",
    "\n",
    "Para usar seu recurso dos Serviços Cognitivos, os aplicativos clientes precisam do ponto de extremidade e da chave de autenticação:\n",
    "\n",
    "1. No portal do Azure, na página **Chaves e ponto de extremidade** do seu recurso dos Serviços Cognitivos, copie a **Chave 1** do recurso e cole no código abaixo, substituindo **YOUR_COG_KEY**.\n",
    "\n",
    "2. Copie o **ponto de extremidade** do recurso e cole no código abaixo, substituindo **YOUR_COG_ENDPOINT**.\n",
    "\n",
    "3. Execute o código abaixo clicando no botão Executar célula <span>&#9655;</span> (no canto superior esquerdo da célula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693964655
    }
   },
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que você tem um recurso dos Serviços Cognitivos, pode usar o serviço de Detecção Facial para detectar rostos humanos na loja.\n",
    "\n",
    "Execute a célula de código abaixo para ver um exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970079
    }
   },
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from python_code import faces\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a face detection client.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada rosto detectado recebe uma ID exclusiva, assim o aplicativo pode identificar cada um deles.\n",
    "\n",
    "Execute a célula abaixo para ver as IDs dos rostos de outros compradores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970447
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisar atributos faciais\n",
    "\n",
    "A Detecção Facial pode fazer muito mais do que simplesmente detectar rostos. Ela pode analisar características e expressões faciais para sugerir a idade e o estado emocional da pessoa. Por exemplo, execute o código abaixo para analisar os atributos faciais de um comprador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693971321
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces and specified facial attributes\n",
    "attributes = ['age', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# Display the faces and attributes (code in python_code/faces.py)\n",
    "faces.show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nas pontuações de emoção detectadas para o cliente na imagem, ele parece estar muito feliz com a experiência de compra.\n",
    "\n",
    "## Encontrar rostos similares \n",
    "\n",
    "As IDs dos rostos que são criadas para face detectada são usadas para identificar detecções faciais individualmente. Você pode usar essas IDs para comparar um rosto detectado com rostos identificados anteriormente e com características semelhantes.\n",
    "\n",
    "Por exemplo, execute a célula abaixo para comparar o comprador de uma imagem com compradores de outra e encontrar um rosto compatível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693972555
    }
   },
   "outputs": [],
   "source": [
    "# Get the ID of the first face in image 1\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# Get the face IDs in a second image\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# Find faces in image 2 that are similar to the one in image 1\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# Show the face in image 1, and similar faces in image 2(code in python_code/face.py)\n",
    "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconhecer rostos\n",
    "\n",
    "Até agora, você viu que a Detecção Facial é capaz de detectar rostos e características faciais, além de identificar rostos parecidos. Você pode levar as coisas um pouco mais além implementando uma solução de *reconhecimento facial*, em que a Detecção Facial é treinada para reconhecer o rosto de uma pessoa específica. Isso pode ser útil em diversos cenários, como a marcação automática de fotos de amigos em um aplicativo de rede social ou o uso de reconhecimento facial como parte de um sistema de verificação biométrica de identidade.\n",
    "\n",
    "Para ver como esse processo funciona, vamos supor que a empresa Northwind Traders queira usar o reconhecimento facial para garantir que somente funcionários autorizados do departamento de TI consigam acessar os sistemas de segurança.\n",
    "\n",
    "Vamos começar criando um *grupo de pessoas* para representar os funcionários autorizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693973492
    }
   },
   "outputs": [],
   "source": [
    "group_id = 'employee_group_id'\n",
    "try:\n",
    "    # Delete group if it already exists\n",
    "    face_client.person_group.delete(group_id)\n",
    "except Exception as ex:\n",
    "    print(ex.message)\n",
    "finally:\n",
    "    face_client.person_group.create(group_id, 'employees')\n",
    "    print ('Group created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que o *grupo de pessoas* existe, podemos adicionar uma *pessoa* para cada funcionário que quisermos incluir no grupo. Depois, registramos várias fotos de cada um deles para que a Detecção Facial aprenda quais são as características faciais distintas de cada pessoa. Idealmente, as imagens devem mostrar a mesma pessoa em poses diferentes e com expressões faciais diferentes.\n",
    "\n",
    "Vamos adicionar um único funcionário chamado Wendell e registrar três fotos dele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693976898
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Add a person (Wendell) to the group\n",
    "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
    "\n",
    "# Get photo's of Wendell\n",
    "folder = os.path.join('data', 'face', 'wendell')\n",
    "wendell_pics = os.listdir(folder)\n",
    "\n",
    "# Register the photos\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for pic in wendell_pics:\n",
    "    # Add each photo to person in person group\n",
    "    img_path = os.path.join(folder, pic)\n",
    "    img_stream = open(img_path, \"rb\")\n",
    "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
    "\n",
    "    # Display each image\n",
    "    img = Image.open(img_path)\n",
    "    i +=1\n",
    "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a pessoa adicionada e as fotografias registradas, podemos treinar a Detecção Facial para reconhecer cada indivíduo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693977046
    }
   },
   "outputs": [],
   "source": [
    "face_client.person_group.train(group_id)\n",
    "print('Trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, com o modelo treinado, você pode usá-lo para identificar rostos reconhecidos em uma imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693994820
    }
   },
   "outputs": [],
   "source": [
    "# Get the face IDs in a second image\n",
    "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
    "\n",
    "# Get recognized face names\n",
    "face_names = {}\n",
    "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
    "for face in recognized_faces:\n",
    "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
    "    face_names[face.face_id] = person_name\n",
    "\n",
    "# show recognized faces\n",
    "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saiba mais\n",
    "\n",
    "Para saber mais sobre o serviço cognitivo de Detecção Facial, consulte a [documentação da Detecção Facial](https://docs.microsoft.com/azure/cognitive-services/face/)\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}