{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classificação de imagem\r\n",
        "\r\n",
        "O serviço cognitivo de *Pesquisa Visual Computacional* oferece modelos predefinidos úteis para trabalhar com as imagens, mas, em geral, você precisará treinar seu próprio modelo para a pesquisa visual computacional. Por exemplo, suponha que a varejista Northwind Traders queira criar um sistema automatizado de finalização de pedidos que identifique os itens que os clientes querem comprar com base em uma imagem captada por uma câmera. Para isso, você precisará treinar um modelo de classificação capaz de classificar as imagens para identificar o item que está sendo comprado.\r\n",
        "\r\n",
        "![Um robô segurando uma prancheta, classificando imagens de uma maçã, uma banana e uma laranja](./images/image-classification.jpg)\r\n",
        "\r\n",
        "No Azure, você pode usar o serviço cognitivo de ***Visão Personalizada*** para treinar um modelo de classificação de imagem com base em imagens existentes. A criação de uma solução de classificação de imagem é composta por dois elementos. Primeiro, é preciso treinar um modelo para reconhecer classes diferentes usando imagens existentes. Depois, quando o modelo estiver treinado, é necessário publicá-lo como um serviço que possa ser consumido por aplicativos.\r\n",
        "\r\n",
        "## Criar um recurso de Visão Personalizada\r\n",
        "\r\n",
        "Para usar o serviço de Visão Personalizada, é preciso ter um recurso do Azure que você possa usar para *treinar* um modelo, e um recurso com o qual possa *publicá-lo* para os aplicativos utilizarem. Esses recursos podem ser gerais dos **Serviços Cognitivos** ou específicos de **Visão Personalizada**. Você pode usar o mesmo recurso de Serviços Cognitivos para essas tarefas ou recorrer a recursos diferentes (na mesma região) para gerenciar os custos separadamente.\r\n",
        "\r\n",
        "Use as instruções a seguir para criar um novo recurso de **Visão Personalizada**.\r\n",
        "\r\n",
        "1. Em uma nova guia do navegador, abra o portal do Azure em [https://portal.azure.com](https://portal.azure.com) e conecte-se usando a conta Microsoft associada à sua assinatura do Azure.\r\n",
        "2. Selecione o botão **&#65291;Criar um recurso**, procure a opção *Visão personalizada* e crie um recurso de **Visão personalizada** com as seguintes configurações:\r\n",
        "    - **Opções de criação**: Ambos\r\n",
        "    - **Assinatura**: *sua assinatura do Azure*\r\n",
        "    - **Grupo de recursos**: *Selecione ou crie um grupo de recursos com um nome exclusivo*\r\n",
        "    - **Nome**: *Insira um nome exclusivo*\r\n",
        "    - **Local de treinamento**: *Escolha qualquer região disponível*\r\n",
        "    - **Tipo de preço de treinamento**: F0\r\n",
        "    - **Local de previsão**: *a mesma região que a do recurso de treinamento*\r\n",
        "    - **Tipo de preço de previsão **: F0\r\n",
        "\r\n",
        "    >**Observação**: se você já tiver um serviço de visão personalizada F0 na sua assinatura, selecione **S0** nesse.\r\n",
        "\r\n",
        "3. Aguarde até que os recursos sejam criados e observe que dois recursos de Visão Personalizada são provisionados: um para o treinamento e outro para a previsão. Você pode visualizá-los navegando até o grupo de recursos onde os criou.\r\n",
        "\r\n",
        "## Criar um projeto de Visão Personalizada\r\n",
        "\r\n",
        "Para treinar um modelo de detecção de objetos, é necessário criar um projeto de Visão Personalizada com base no seu recurso de treinamento. Para isso, você usará o portal Visão Personalizada.\r\n",
        "\r\n",
        "1. Faça download e extraia as imagens de treinamento em https://aka.ms/fruit-images. **Observação:** como uma solução alternativa temporária, caso você não consiga acessar as imagens de treinamento, acesse https://www.github.com e depois https://aka.ms/fruit-images.  \r\n",
        "2. Em outra guia do navegador, abra o portal de Visão Personalizada em [https://customvision.ai](https://customvision.ai). Caso seja solicitado, entre com a conta Microsoft associada à sua assinatura do Azure e concorde com os termos de serviço.\r\n",
        "3. No portal de Visão Personalizada, crie um novo projeto com as seguintes configurações:\r\n",
        "    - **Nome**: Grocery Checkout\r\n",
        "    - **Descrição**: Classificação de imagem de alimentos\r\n",
        "    - **Recurso**: *o recurso de Visão Personalizada que você criou anteriormente*\r\n",
        "    **- Tipos de projeto**: Classificação\r\n",
        "    - **Tipos de Classificação**: Multiclasse (marca única por imagem)\r\n",
        "    - **Domínios**: Alimentação\r\n",
        "4. Clique em **\\[+\\] Adicionar imagens** e selecione todos os arquivos da pasta **maçã** que você extraiu anteriormente. Em seguida, faça upload dos arquivos de imagem, especificando a marca *maçã*, dessa forma:\r\n",
        "\r\n",
        "![Upload de uma maçã com a marca maçã](./images/upload_apples.jpg)\r\n",
        "   \r\n",
        "5. Repita a etapa anterior para fazer upload das imagens na pasta **banana** com a marca *banana* e as imagens da pasta **laranja** com a marca *laranja*.\r\n",
        "6. Explore as imagens que você enviou para o projeto de Visão Personalizada. Deve haver 15 imagens de cada classe, dessa forma:\r\n",
        "\r\n",
        "![Imagens marcadas de frutas: 15 maçãs, 15 bananas e 15 laranjas](./images/fruit.jpg)\r\n",
        "    \r\n",
        "7. No projeto de Visão Personalizada, acima das imagens, clique em **Treinar** para treinar um modelo de classificação usando as imagens marcadas. Selecione a opção **Treinamento rápido** e aguarde a iteração do treinamento ser concluída (esse processo pode levar um minuto ou mais).\r\n",
        "8. Quando a iteração do modelo for treinada, analise as métricas de desempenho *Precisão*, *Recall* e *AP* – elas medem a precisão da previsão do modelo de classificação e devem ser altas.\r\n",
        "\r\n",
        "## Testar o modelo\r\n",
        "\r\n",
        "Antes de publicar essa iteração do modelo para que os aplicativos possam usar, é preciso testá-la.\r\n",
        "\r\n",
        "1. Acima das métricas de desempenho, clique em **Teste rápido**.\r\n",
        "2. Na caixa **URL da imagem**, digite `https://aka.ms/apple-image` e clique em &#10132;\r\n",
        "3. Veja as previsões retornadas pelo modelo. A pontuação de probabilidade de *maçã* deve ser a mais alta, dessa forma:\r\n",
        "\r\n",
        "![Uma imagem com uma previsão de classe de maçã](./images/test-apple.jpg)\r\n",
        "\r\n",
        "4. Feche a janela de **Teste rápido**.\r\n",
        "\r\n",
        "## Publicar e consumir o modelo de classificação de imagem\r\n",
        "\r\n",
        "Agora você está pronto para publicar seu modelo treinado e usá-lo em um aplicativo cliente.\r\n",
        "\r\n",
        "9. Clique em **&#128504; Publicar** para publicar o modelo treinado com as seguintes configurações:\r\n",
        "    - **Nome do modelo**: groceries\r\n",
        "    - **Recurso de previsão**: *o recurso de previsão que você criou anteriormente*.\r\n",
        "\r\n",
        "### (!) Verificação \r\n",
        "Você usou o mesmo nome do modelo: **groceries**?   \r\n",
        "\r\n",
        "10. Depois de publicar, clique no ícone de *configurações* (&#9881;) no canto superior direito da página de **Desempenho** para visualizar as configurações do projeto. Na seção **Geral** (à esquerda), copie a **ID do projeto**. Role para baixo e cole-o na célula de código debaixo da etapa 13, substituindo **YOUR_PROJECT_ID**.\r\n",
        "\r\n",
        "![ID do projeto nas configurações do projeto](./images/cv_project_settings.jpg)\r\n",
        "\r\n",
        "> _**Observação**: Se você tiver usado um recurso dos **Serviços Cognitivos** em vez de criar um recurso de **Visão Personalizada** no início deste exercício, poderá copiar a chave e o ponto de extremidade correspondentes no lado direito das configurações do projeto, colar esses dados na célula de código abaixo e executá-la para ver os resultados. Caso contrário, continue concluindo as etapas abaixo para obter a chave e o ponto de extremidade do seu recurso de previsão de Visão Personalizada._\r\n",
        "\r\n",
        "11. No canto superior esquerdo da página **Configurações do projeto**, clique no ícone das *Galeria de projetos* (&#128065;) para voltar à página inicial do portal de Visão Personalizada, onde seu projeto estará listado agora.\r\n",
        "\r\n",
        "12. Na página inicial do portal de Visão Personalizada, no canto superior direito, clique no ícone de *configurações* (&#9881;) para visualizar as configurações do seu serviço de Visão Personalizada. Depois, na seção **Recursos**, expanda o recurso de **previsão** (<u>não</u> o de treinamento) e copie os valores correspondentes de **Chave** e **Ponto de extremidade** na célula de código abaixo da etapa 13, substituindo **YOUR_KEY** e **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) Verificação \r\n",
        "Caso esteja usando um recurso de **Visão Personalizada**, você usou o recurso de **previsão** (<u>não</u> o de treinamento)?\r\n",
        "\r\n",
        "![Chave e ponto de extremidade do recurso de previsão nas configurações de Visão Personalizada](./images/cv_settings.jpg)\r\n",
        "\r\n",
        "13. Execute a célula de código abaixo clicando no botão **Executar célula** (&#9655;) (à esquerda) para definir as variáveis como os valores de ID do projeto, chave e ponto de extremidade."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\r\n",
        "cv_key = 'YOUR_KEY'\r\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\r\n",
        "\r\n",
        "model_name = 'groceries' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\r\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora você pode usar sua chave e ponto de extremidade com um cliente de Visão Personalizada para se conectar ao modelo de classificação de visão personalizada.\r\n",
        "\r\n",
        "Execute a célula de código abaixo para classificar uma seleção de imagens de teste usando seu modelo publicado.\r\n",
        "\r\n",
        "> **Observação**: Não se preocupe muito com os detalhes do código. Ele usa o SDK de Pesquisa Visual Computacional do Python para obter uma previsão de classe de cada uma das imagens da pasta /data/image-classification/test-fruit"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
        "from msrest.authentication import ApiKeyCredentials\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# Get the test images from the data/vision/test folder\r\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\r\n",
        "test_images = os.listdir(test_folder)\r\n",
        "\r\n",
        "# Create an instance of the prediction service\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\r\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\r\n",
        "\r\n",
        "# Create a figure to display the results\r\n",
        "fig = plt.figure(figsize=(16, 8))\r\n",
        "\r\n",
        "# Get the images and show the predicted classes for each one\r\n",
        "print('Classifying images in {} ...'.format(test_folder))\r\n",
        "for i in range(len(test_images)):\r\n",
        "    # Open the image, and use the custom vision model to classify it\r\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\r\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\r\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\r\n",
        "    prediction = classification.predictions[0].tag_name\r\n",
        "    # Display the image with its predicted class\r\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\r\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\r\n",
        "    a.axis('off')\r\n",
        "    imgplot = plt.imshow(img)\r\n",
        "    a.set_title(prediction)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por sorte, seu modelo de classificação de imagem identificou corretamente os alimentos nas imagens.\r\n",
        "\r\n",
        "## Saiba mais\r\n",
        "\r\n",
        "O serviço de Visão Personalizada oferece mais recursos do que nós exploramos neste exercício. Por exemplo, também é possível usar o serviço de Visão Personalizada para criar modelos de *detecção de objetos*, que não só classificam objetos nas imagens, mas também identificam *caixas delimitadoras* que mostram a localização do objeto na imagem.\r\n",
        "\r\n",
        "Para saber mais sobre o serviço cognitivo de Visão Personalizada, consulte a [documentação da Visão Personalizada](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}